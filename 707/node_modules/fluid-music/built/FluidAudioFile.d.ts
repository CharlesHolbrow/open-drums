/** AudioFile playback modes */
export declare enum AudioFileMode {
    /**
     * In this default mode, a `'1234'` rhythm  string, combined with a `'s...'`
     * will trim the length of the inserted audio file to a quarter note. */
    Event = 1,
    /**
     * The OneShot mode plays the file to its conclusion, ignoring the event
     * length extracted from the pattern string */
    OneShot = 2,
    /**
     * Play the audio file to its conclusion, OR fade it out at the onset of the
     * next AudioFile in the clip (whichever happens first) */
    OneVoice = 3
}
/**
 * Audio file details provided by the music-metadata npm package.
 */
export interface AudioFileInfo {
    [key: string]: any;
    /** length in seconds */
    duration?: number;
    bitsPerSample?: number;
    sampleRate?: number;
    numberOfChannels?: number;
}
/** Named positions within the source file, described in seconds */
export interface AudioFileMarkers {
    [key: string]: number;
}
export interface AudioFileOptions extends AudioFileConfig {
    path: string;
}
export interface AudioFileConfig {
    path?: string;
    fadeOutSeconds?: number;
    fadeInSeconds?: number;
    gainDb?: number;
    mode?: AudioFileMode;
    info?: AudioFileInfo;
    startInSourceSeconds?: number;
    startTimeSeconds?: number;
    durationSeconds?: number;
    playbackRate?: number;
    markers?: {
        [key: string]: number;
    } | Map<string, number>;
}
/**
 * FluidAudioFile is a non-destructive reference to static audio asset. Think of
 * it like an "Item" in Reaper or an "Audio Clip" in Tracktion Waveform.
 *
 * It is unusual that you use `FluidAudioFile` directly. More often you will
 * create and interact with the [[`AudioFile | fluid.techniques.AudioFile`]]
 * derived class. Note that unlike the technique version, `FluidAudioFile` does
 * not have a `.use` method so a `FluidAudioFile` instance is not a `Technique`,
 * and cannot be used in a technique library.
 *
 * However, most of the methods for manipulating audio files on the timeline are
 * defined in this class, so the documentation here is likely to be informative.
 */
export declare class FluidAudioFile {
    constructor(options: AudioFileOptions);
    static Modes: typeof AudioFileMode;
    /** path to the underlying audio file */
    path: string;
    /** Fade out time in seconds */
    fadeOutSeconds: number;
    /** Fade in time in seconds */
    fadeInSeconds: number;
    /** Gain in dBFS applied to the sample. 0 is unity gain */
    gainDb: number;
    mode: AudioFileMode;
    /** Information and metadata pertaining to the source audio file */
    info: AudioFileInfo;
    /** Named events within the source file */
    markers: Map<string, number>;
    /** The time within the parent (track) that this sample will be triggered */
    startTimeSeconds: number;
    /**
     * durationSeconds specifies the length of the playback event measured on the
     * main timeline. To calculate where in the source audio file playback ends,
     * use `.getEndInSourceSeconds()`.
     */
    durationSeconds: number;
    /**
     * startInSourceSeconds specifies the beginning of the region of interest
     * within the audio source file. Set this to zero to play from the beginning.
     * This measures the start point within the source material, assuming a 1x
     * `.playbackRate` (even when `this.playbackRate != 1`). Notice that you
     * cannot use `startInSourceSeconds + durationSeconds` to calculate the
     * "endInSourceSeconds".
     *
     * To calculate the position in the source audio file that playback ends, use
     * `.getEndInSourceSeconds()`, which correctly accounts for the value of
     * `.playbackRate`.
     */
    startInSourceSeconds: number;
    playbackRate: number;
    /**
     * Check the AudioFile for potential problems. If problems are found, return
     * an error message string. Otherwise, return null
     */
    check(): string | null;
    /**
     * Convenience method for setting audio file markers
     * @param markers
     */
    setMarkers(markers: {
        [key: string]: number;
    } | Map<string, number>): void;
    /**
     * Reverse the audio file playback, swapping the in/out fades.
     * @param reverse If true, play audio file in reverse. If false, play forwards
     */
    reverse(bool?: boolean): number;
    /**
     * Identify where within the source file playback will end, given the values
     * of `.startInSourceSeconds`, `.durationSeconds`, and `.playbackRate`.
     */
    getEndInSourceSeconds(): number;
    isReversed(): boolean;
    /**
     * Calculate and return the maximum valid value for `.durationSeconds`.
     *
     * Setting the `.durationSeconds` value to the value returned by this function
     * will result in the underlying audio file being played to the end of the
     * underlying audio source object (or to the beginning, if `.playbackRate` is
     * negative.
     *
     * ```
     * audioFile.durationSeconds = audioFile.getMaxDurationSeconds()
     * ```
     *
     * When the file is NOT reversed, the source file length is used, so make sure
     * that `audioFile.info.duration` exists.
     */
    getMaxDurationSeconds(): number;
    /**
     * Return the length of the source audio file in seconds. If the length is not
     * included in .info, print a WARNING message, and return an arbitrary value.
     */
    getSourceDurationSeconds(): number;
    /**
     * Return the length of the source audio file given the current .playbackRate.
     * This will be the maximum length of the event, assuming the value of
     * .startInSource does not trim the fileEvent.
     */
    getSourcePlaybackSeconds(): number;
    /**
     * The "right tail" is the source content that gets truncated during playback
     * when (for example), the `.durationSeconds` ends playback before the end
     * of the underlying source audio file.
     *
     * If source audio file duration is 5 seconds, and the `.durationSeconds`
     * property is 4 seconds, then the "right tail" will be 1 second (assuming
     * `.playbackRate == 1` and `.startInSourceSeconds == 0`).
     *
     * This method will calculate the duration of the trailing tail even when
     * audio is playing in reverse (because of a negative `.playbackRate` or when
     * `.startInSourceSeconds != 0`).
     *
     * Note that there is an inverse relationship between the absolute value of
     * `.playbackRate` and the tail length, because slowing the playback rate of
     * the source file effectively increases the length of the underlying sample.
     *
     * @returns A duration (measured in seconds on the timeline) of the trailing
     * tail of this audio item.
     */
    getTailRightSeconds(): number;
    /**
     * The "left tail" is the source content that gets trimmed during playback
     * when (for example), the `.startInSourceSeconds` offsets the beginning
     * of the playback within the underlying source audio file.
     *
     * If the `.startInSourceSeconds` property is 1, then the "left tail" will
     * also be 1 (assuming `.playbackRate == 1` and `.startInSourceSeconds == 0`).
     *
     * This method will calculate the duration of the lead-in tail even when
     * audio is playing in reverse (because of a negative `.playbackRate`)
     *
     * Note that there is an inverse relationship between the absolute value of
     * `.playbackRate` and the tail length, because slowing the playback rate of
     * the source file effectively increases the length of the underlying sample.
     *
     * @returns A duration (measured in seconds on the timeline) of the lead-in
     * tail of this audio item.
     */
    getTailLeftSeconds(): number;
    /**
     * Move the right edge of the item without moving the contents of the item on
     * the timeline.
     *
     * @param seconds Positive values make the item longer by moving the right
     * edge to the right. Negative values make the item shorter by moving the
     * right edge to the left. This value is be measured on the timeline, and not
     * in the audiofile source (an important distinction when
     * `this.playbackRate != 1`).
     */
    growRightEdgeBySeconds(seconds: number): void;
    growRightEdgeBySecondsSafe(seconds: number): void;
    /**
     * Move the left edge of the item without moving the contents of the item on
     * the timeline.
     *
     * @param seconds Positive values make the item longer by moving the left edge
     * to the left. Negative values make the item shorter by moving the left edge
     * to the right. This value is be measured on the timeline, and not in the
     * audiofile source (an important distinction when `this.playbackRate != 1`).
     */
    growLeftEdgeBySeconds(seconds: number): void;
    growLeftEdgeBySecondsSafe(seconds: number): void;
    /**
     * Set the event's `.durationSeconds` so that it plays right up to the end of
     * the source. This takes into account `.playbackRate`, `.isReversed()`, and
     * `.startInSourceSeconds`.
     */
    playToEnd(): void;
}
/**
 * `resolveFades` is used internally to account for the case when an audio file's
 * in and out fades are longer than the item containing the audio file itself.
 * You may set an audio file's `.fadeInSeconds` to a value that is longer than
 * the duration of the audio file instance on a track. Exporters use this method
 * to simulate a long fade in by artificially reducing the audioFile's gain.
 *
 * This prevents short clips with long gains from fading in faster than they
 * should. If you want to avoid this behavior, make sure that the total
 * `.fadeInSeconds` and `.fadeOutSeconds` in your audio files do not exceed the
 * `.durationSeconds`.
 */
export declare function resolveFades(audioFile: FluidAudioFile): {
    fadeInSeconds: number;
    fadeOutSeconds: number;
    gainDb: number;
};
